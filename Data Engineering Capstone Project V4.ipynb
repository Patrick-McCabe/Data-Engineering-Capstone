{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project is focused on an extract, transform, and load (ETL) process that incorporates I94 immigration, demographic and temperature data of cities within the United States.  Raw data is staged, cleaned, and assembled into a data model for further analysis. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "    * I94 Immigration Data\n",
    "    * US Cities Demographics\n",
    "    * World Temperature Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do all imports and installs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import glob\n",
    "import configparser\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql.functions import udf,to_date, date_add, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear\n",
    "import pyspark.sql.functions as f\n",
    "import etl_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Spark Session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#The saurfang packages allow reading SAS binary file (.sas7bdat) in parallel as data frame in Spark SQL. \n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Project Scope \n",
    "This project utilizes pandas software library and the Spark Python API (PySpark) to assemble raw data from three sources into a relational database which can easily be queried for analysis. Data is extracted from csv and sas files and staged within dataframes.  An analysis of each dataframe is performed to determine the structure, flaws, and characteristics of each dataframe.  A cleaning process resolves any identified flaws which may include missing values, duplicate rows, erroneous data etc.  \n",
    "    \n",
    "The dataframes are eventually  split into tables, compiling a data model used for ongoing data analysis. The data model was designed with a focus on US immigration and US city demographics and US temperatures.  Data for areas outside the US have been dropped during the cleaning process. End users are able to query the data to determine where immigration is focused and analyze those areas with regard to their historic temperatures and social demographics as of 2015. \n",
    "\n",
    "#### Describe and Gather Data \n",
    "* __I94 Immigration Data:__ This data comes from the US National Tourism and Trade Office. To enter the United States, all non-U.S. citizens from overseas countries traveling by air or sea must complete an I94 form.  The I94 forms are compiled into a database that provides a count of visitor arrivals to the United States (with stays of 1-night or more and visiting under certain visa types) to calculate U.S. travel and tourism volume exports.  \n",
    "* __World Temperature Data:__ Originally compiled by the Berkeley Earth, which is affiliated with Lawrence Berkeley National Laboratory, this is a subset of a database that combines 1.6 billion temperature reports from 16 pre-existing archives.  The records start in 1750 for average land temperature and 1850 for max and min land temperatures and global ocean and land temperatures.\n",
    "* __U.S. City Demographic Data:__ This dataset contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000. The data comes from the US Census Bureau's 2015 American Community Survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### US Cities Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read demographics data\n",
    "#demographics_df = spark.read.format(\"csv\").option(\"delimiter\", \";\").option(\"header\", \"true\").load(\"us-cities-demographics.csv\")\n",
    "demographics_df = pd.read_csv(\"us-cities-demographics.csv\", sep = \";\")\n",
    "demographics_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096313, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data here from sas file\n",
    "immigration_df = spark.read.parquet(\"sas_data\")\n",
    "immigration_df.count(), len(immigration_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8599212, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data here from csv file\n",
    "#temperature_df = spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv',header = True, inferSchema = True)\n",
    "temperature_df = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "temperature_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographic Data Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>Yuma</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.4</td>\n",
       "      <td>48298.0</td>\n",
       "      <td>45847.0</td>\n",
       "      <td>94145</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>19326.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>AZ</td>\n",
       "      <td>White</td>\n",
       "      <td>69691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>Yuma</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.4</td>\n",
       "      <td>48298.0</td>\n",
       "      <td>45847.0</td>\n",
       "      <td>94145</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>19326.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>57054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>Yuma</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.4</td>\n",
       "      <td>48298.0</td>\n",
       "      <td>45847.0</td>\n",
       "      <td>94145</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>19326.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>3731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>Yuma</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.4</td>\n",
       "      <td>48298.0</td>\n",
       "      <td>45847.0</td>\n",
       "      <td>94145</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>19326.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Asian</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>Yuma</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.4</td>\n",
       "      <td>48298.0</td>\n",
       "      <td>45847.0</td>\n",
       "      <td>94145</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>19326.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>AZ</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      City    State  Median Age  Male Population  Female Population  \\\n",
       "875   Yuma  Arizona        33.4          48298.0            45847.0   \n",
       "1084  Yuma  Arizona        33.4          48298.0            45847.0   \n",
       "2105  Yuma  Arizona        33.4          48298.0            45847.0   \n",
       "1619  Yuma  Arizona        33.4          48298.0            45847.0   \n",
       "2859  Yuma  Arizona        33.4          48298.0            45847.0   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "875              94145              7182.0       19326.0   \n",
       "1084             94145              7182.0       19326.0   \n",
       "2105             94145              7182.0       19326.0   \n",
       "1619             94145              7182.0       19326.0   \n",
       "2859             94145              7182.0       19326.0   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "875                     2.64         AZ                              White   \n",
       "1084                    2.64         AZ                 Hispanic or Latino   \n",
       "2105                    2.64         AZ          Black or African-American   \n",
       "1619                    2.64         AZ                              Asian   \n",
       "2859                    2.64         AZ  American Indian and Alaska Native   \n",
       "\n",
       "      Count  \n",
       "875   69691  \n",
       "1084  57054  \n",
       "2105   3731  \n",
       "1619   1180  \n",
       "2859   1228  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display sample of Demographic Data\n",
    "demographics_df.sort_values(\"City\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#Display columns and data types of each\n",
    "demographics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the number of rows and columns in demographics_df\n",
    "demographics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "State                      0\n",
       "Median Age                 0\n",
       "Male Population            3\n",
       "Female Population          3\n",
       "Total Population           0\n",
       "Number of Veterans        13\n",
       "Foreign-born              13\n",
       "Average Household Size    16\n",
       "State Code                 0\n",
       "Race                       0\n",
       "Count                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the number of null values in each column of Demographic Data, it appears the data has relatively few null values\n",
    "demographics_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of unique City values is much smaller than the total number of rows indicating the City column contains many duplicates\n",
    "demographics_df['City'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Duplicate_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>Texas</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Pasadena</td>\n",
       "      <td>Texas</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Palm Coast</td>\n",
       "      <td>Florida</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Palmdale</td>\n",
       "      <td>California</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>California</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           City       State  Duplicate_Count\n",
       "0       Abilene       Texas                5\n",
       "392    Pasadena       Texas                5\n",
       "386  Palm Coast     Florida                5\n",
       "387    Palmdale  California                5\n",
       "388   Palo Alto  California                5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new dataframe called cityStateDuplicate to display the number of times a city and state combination is duplicated. \n",
    "#It appears City values are duplicated up to 5 times. \n",
    "cityStateDuplicate = demographics_df.groupby([\"City\", \"State\"]).size().reset_index(name=\"Duplicate_Count\")\n",
    "cityStateDuplicate.sort_values(\"Duplicate_Count\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Pasadena</td>\n",
       "      <td>California</td>\n",
       "      <td>37.6</td>\n",
       "      <td>67712.0</td>\n",
       "      <td>74534.0</td>\n",
       "      <td>142246</td>\n",
       "      <td>4618.0</td>\n",
       "      <td>40779.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>CA</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>52717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>Pasadena</td>\n",
       "      <td>California</td>\n",
       "      <td>37.6</td>\n",
       "      <td>67712.0</td>\n",
       "      <td>74534.0</td>\n",
       "      <td>142246</td>\n",
       "      <td>4618.0</td>\n",
       "      <td>40779.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>CA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>2161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>Pasadena</td>\n",
       "      <td>California</td>\n",
       "      <td>37.6</td>\n",
       "      <td>67712.0</td>\n",
       "      <td>74534.0</td>\n",
       "      <td>142246</td>\n",
       "      <td>4618.0</td>\n",
       "      <td>40779.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>CA</td>\n",
       "      <td>White</td>\n",
       "      <td>76525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>Pasadena</td>\n",
       "      <td>California</td>\n",
       "      <td>37.6</td>\n",
       "      <td>67712.0</td>\n",
       "      <td>74534.0</td>\n",
       "      <td>142246</td>\n",
       "      <td>4618.0</td>\n",
       "      <td>40779.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>15909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>Pasadena</td>\n",
       "      <td>California</td>\n",
       "      <td>37.6</td>\n",
       "      <td>67712.0</td>\n",
       "      <td>74534.0</td>\n",
       "      <td>142246</td>\n",
       "      <td>4618.0</td>\n",
       "      <td>40779.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>22794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          City       State  Median Age  Male Population  Female Population  \\\n",
       "514   Pasadena  California        37.6          67712.0            74534.0   \n",
       "1261  Pasadena  California        37.6          67712.0            74534.0   \n",
       "1948  Pasadena  California        37.6          67712.0            74534.0   \n",
       "2855  Pasadena  California        37.6          67712.0            74534.0   \n",
       "2856  Pasadena  California        37.6          67712.0            74534.0   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "514             142246              4618.0       40779.0   \n",
       "1261            142246              4618.0       40779.0   \n",
       "1948            142246              4618.0       40779.0   \n",
       "2855            142246              4618.0       40779.0   \n",
       "2856            142246              4618.0       40779.0   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "514                     2.63         CA                 Hispanic or Latino   \n",
       "1261                    2.63         CA  American Indian and Alaska Native   \n",
       "1948                    2.63         CA                              White   \n",
       "2855                    2.63         CA          Black or African-American   \n",
       "2856                    2.63         CA                              Asian   \n",
       "\n",
       "      Count  \n",
       "514   52717  \n",
       "1261   2161  \n",
       "1948  76525  \n",
       "2855  15909  \n",
       "2856  22794  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the 'Pasadena' and 'California' as an example combination, it appears City values are being duplicated to account for different Race values being split into separate rows.\n",
    "demographics_df[(demographics_df.City == 'Pasadena') & (demographics_df.State == 'California')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hispanic or Latino', 'White', 'Asian', 'Black or African-American',\n",
       "       'American Indian and Alaska Native'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the unique values found in the Race column\n",
    "demographics_df.Race.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#It's clear Cities are being duplicated due to their number of unique races, to aid further analysis, the 'Duplicate_Count' column is renamed 'Unique_Races'.\n",
    "cityStateDuplicate = cityStateDuplicate.rename(columns={'Duplicate_Count': 'Unique_Races'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the number of times a city, state and race combination is duplicated.  \n",
    "#The result shows the Race value(eg. 'White', 'Asian' etc.) is not duplicated for any City and State combination, meaning each City and State combination has one row for each race value. \n",
    "cityStateRaceDuplicates = demographics_df.groupby([\"City\", \"State\",\"Race\"]).size().reset_index(name=\"Duplicate_Count\")\n",
    "cityStateRaceDuplicates[(cityStateRaceDuplicates.Duplicate_Count > 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "      <th>Unique_Races</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  Unique_Races  \n",
       "0                    2.60         MD  Hispanic or Latino  25924             5  \n",
       "1                    2.39         MA               White  58723             5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create new dataframe called demographics_df_WithRaceCount that includes the number of unique race values for each City State combination.\n",
    "#The number of rows remains the same and one column has been added; the Duplicate_Count column.\n",
    "demographics_df_WithRaceCount = demographics_df.merge(cityStateDuplicate, how = 'left', on = ['City', 'State'])\n",
    "print(demographics_df_WithRaceCount.shape)\n",
    "demographics_df_WithRaceCount.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create spark Dataframe from demographics_df_WithRaceCount\n",
    "spark_demographics_df_WithRaceCount = spark.createDataFrame(demographics_df_WithRaceCount)\n",
    "#spark_demographics_df_WithRaceCount.createOrReplaceTempView('spark_demog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#596 Rows of Unique City, State Combinations\n",
    "len(demographics_df.groupby([\"City\", \"State\"]).nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596 7\n",
      "+--------------------+--------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|                City|   State|American Indian and Alaska Native|Asian|Black or African-American|Hispanic or Latino| White|\n",
      "+--------------------+--------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|          Cincinnati|    Ohio|                             3362| 7633|                   133430|              9121|162245|\n",
      "|           Lynchburg|Virginia|                             1024| 2910|                    23271|              2689| 53727|\n",
      "|         Kansas City|  Kansas|                             2749| 7301|                    40177|             44342| 96113|\n",
      "|Louisville/Jeffer...|Kentucky|                             4585|18601|                   151256|             28712|456451|\n",
      "|              Dayton|    Ohio|                             2010| 1885|                    57280|              4945| 86016|\n",
      "+--------------------+--------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create new dataframe to pivot races into column headers.  This data frame has one row for each city and five columns, one for each race.\n",
    "#The number of rows matches the original number of unique city, state combinations, confirming no cities were duplicated.\n",
    "City_Race_Table = spark_demographics_df_WithRaceCount.groupBy([\"City\", \"State\"]).pivot('Race').sum('Count')\n",
    "print(City_Race_Table.count(), len(City_Race_Table.columns))\n",
    "City_Race_Table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unique_Races</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Total Population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>145921.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>89036.750000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>103763.600000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>82388.265306</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>209019.892655</td>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unique_Races Total Population      \n",
       "                           mean count\n",
       "0            1    145921.000000     2\n",
       "1            2     89036.750000     8\n",
       "2            3    103763.600000    30\n",
       "3            4     82388.265306   196\n",
       "4            5    209019.892655  2655"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of unique Race values varies by City and appears to correlate with a city's total population.\n",
    "#The table below groups the dataframe by Unique_Races(1-5) and provides the mean and count of rows in each Unique_Races category.\n",
    "#This confirms the idea that higher numbers of Unique_Races exist in cities with higher populations\n",
    "demographics_df_WithRaceCount.groupby('Unique_Races', as_index=False).agg({'Total Population': ['mean', 'count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Unique_Races</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>8550405</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>8550405</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>8550405</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>8550405</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>8550405</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total Population  Unique_Races\n",
       "1826           8550405             5\n",
       "2225           8550405             5\n",
       "2493           8550405             5\n",
       "2304           8550405             5\n",
       "2494           8550405             5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the demographics_df_WithRaceCount dataframe is reduced to two columns to create a graph to better illustrate the table above. \n",
    "cityStateDuplicate_reduced = demographics_df_WithRaceCount[['Total Population', 'Unique_Races']].copy()\n",
    "cityStateDuplicate_reduced.sort_values(\"Total Population\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4226098278>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The chart below further illustrates the coorilation between higher Unique_Races values and higher Total Population values.\n",
    "demographics_df_WithRaceCount.plot(kind='scatter',y = \"Unique_Races\", x = \"Total Population\").set_xlim(0,5000000)\n",
    "x = demographics_df_WithRaceCount[\"Total Population\"]\n",
    "y = demographics_df_WithRaceCount[\"Unique_Races\"]\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='yellow')\n",
    "plt.title('A plot to show the correlation between Population Size and Unique_Races Value')\n",
    "plt.xlabel('Total Population')\n",
    "plt.ylabel('Unique_Races')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(City='Cincinnati', State='Ohio', American Indian and Alaska Native=3362, Asian=7633, Black or African-American=133430, Hispanic or Latino=9121, White=162245)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df_WithRaceCount = etl_functions.add_raceCount_to_demographics(spark, demographics_df)\n",
    "demographics_df_WithRaceCount.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Immigration Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "_Column Name - Description_\n",
    "* cicidUnique - record ID\n",
    "* i94yr - 4 digit year\n",
    "* i94mon - Numeric month\n",
    "* i94cit - 3 digit code for immigrant country of birth\n",
    "* i94res - 3 digit code for immigrant country of residence\n",
    "* i94port - Port of admission \n",
    "* arrdate - Arrival Date in the USA\n",
    "* i94mode - Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)\n",
    "* i94addr - USA State of arrival\n",
    "* depdate - Departure Date from the USA\n",
    "* i94bir - Age of Respondent in Years\n",
    "* i94visa - Visa codes collapsed into three categories\n",
    "* count - Field used for summary statistics\n",
    "* dtadfile - Character Date Field - Date added to I-94 Files\n",
    "* visapost - Department of State where where Visa was issued\n",
    "* occup - Occupation that will be performed in U.S\n",
    "* entdepa - Arrival Flag - admitted or paroled into the U.S.\n",
    "* entdepd - Departure Flag - Departed, lost I-94 or is deceased\n",
    "* entdepu - Update Flag - Either apprehended, overstayed, adjusted to perm residence\n",
    "* matflag - Match flag - Match of arrival and departure records\n",
    "* biryear - 4 digit year of birth\n",
    "* dtaddto - Character Date Field - Date to which admitted to U.S. (allowed to stay until)\n",
    "* gender - Non-immigrant sex\n",
    "* insnum - INSnumber \n",
    "* airline - Airline used to arrive in U.S.\n",
    "* admnum - Admission Number\n",
    "* fltno - Flight number of Airline used to arrive in U.S.\n",
    "* visatype - Class of admission legally admitting the non-immigrant to temporarily stay in U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096313, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the shape of immigration_df\n",
    "immigration_df.count(), len(immigration_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display the schema of immigration_df\n",
    "immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entdepu</th>\n",
       "      <td>3095921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occup</th>\n",
       "      <td>3088187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insnum</th>\n",
       "      <td>2982605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visapost</th>\n",
       "      <td>1881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>414269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94addr</th>\n",
       "      <td>152592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depdate</th>\n",
       "      <td>142457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matflag</th>\n",
       "      <td>138429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entdepd</th>\n",
       "      <td>138429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline</th>\n",
       "      <td>83627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fltno</th>\n",
       "      <td>19549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94bir</th>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biryear</th>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtaddto</th>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94mode</th>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entdepa</th>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtadfile</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admnum</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cicid</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94yr</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94visa</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrdate</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94port</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94res</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94cit</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94mon</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visatype</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count\n",
       "entdepu   3095921\n",
       "occup     3088187\n",
       "insnum    2982605\n",
       "visapost  1881250\n",
       "gender     414269\n",
       "i94addr    152592\n",
       "depdate    142457\n",
       "matflag    138429\n",
       "entdepd    138429\n",
       "airline     83627\n",
       "fltno       19549\n",
       "i94bir        802\n",
       "biryear       802\n",
       "dtaddto       477\n",
       "i94mode       239\n",
       "entdepa       238\n",
       "dtadfile        1\n",
       "admnum          0\n",
       "cicid           0\n",
       "i94yr           0\n",
       "count           0\n",
       "i94visa         0\n",
       "arrdate         0\n",
       "i94port         0\n",
       "i94res          0\n",
       "i94cit          0\n",
       "i94mon          0\n",
       "visatype        0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the count of null and NaN values in each column\n",
    "#Although some rows have a relatively high number of null or Nan values, they shouldn't impact final analysis, no null values will be dropped. \n",
    "from pyspark.sql.functions import isnan, isnull, when, count, col\n",
    "nullValues = immigration_df.select([count(when(isnan(c) | isnull(c), c)).alias(c) for c in immigration_df.columns]).toPandas()\n",
    "nullValues.rename(index={0: 'count'}).T.sort_values(\"count\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  152592|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To verify the informaiton above, a duplicate query is perfomed on column i94addr\n",
    "immigration_df.createOrReplaceTempView('ImmigrationTable')\n",
    "spark.sql(\"SELECT count(*) from ImmigrationTable WHERE i94addr IS NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096313, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#An attempt to drop rows that contain all missing values indicates none exist. \n",
    "immigration_df = immigration_df.na.drop(\"all\")\n",
    "immigration_df.count(), len(immigration_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_df.createOrReplaceTempView('Immigration_Fact_Table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(cicid=5748517.0, i94yr=2016.0, i94mon=4.0, i94cit=245.0, i94res=438.0, i94port='LOS', arrdate=20574.0, i94mode=1.0, i94addr='CA', depdate=20582.0, i94bir=40.0, i94visa=1.0, count=1.0, dtadfile='20160430', visapost='SYD', occup=None, entdepa='G', entdepd='O', entdepu=None, matflag='M', biryear=1976.0, dtaddto='10292016', gender='F', insnum=None, airline='QF', admnum=94953870030.0, fltno='00011', visatype='B1', arrival_date_1=datetime.date(2016, 4, 30))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The 'arrdate' field indicates days since Jan. 1 1960 which is converted here to a usable date format and added to a new column titled 'arrival date'.\n",
    "immigration_df = spark.sql(\"SELECT *, date_add(to_date('1960-01-01'), arrdate) AS arrival_date_1 FROM Immigration_Fact_Table\")\n",
    "immigration_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- arrival_date_1: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Immigration_Fact_Table.shema, the new arrival_date_1 column is seen at the bottom of the schema.\n",
    "immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      "dt                               object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 459.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Display the columns and data types of temperature_df.  There are 8599212 rows and 7 columns.\n",
    "temperature_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Convert the dt column to a date data type\n",
    "temperature_df['dt'] = pd.to_datetime(temperature_df['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      "dt                               datetime64[ns]\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: datetime64[ns](1), float64(2), object(4)\n",
      "memory usage: 459.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Confirm the dt column is now data type datetime64\n",
    "temperature_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Duplicate_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>India</td>\n",
       "      <td>1014906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>China</td>\n",
       "      <td>827802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>United States</td>\n",
       "      <td>687289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>475580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Russia</td>\n",
       "      <td>461234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Country  Duplicate_Count\n",
       "66           India          1014906\n",
       "29           China           827802\n",
       "151  United States           687289\n",
       "18          Brazil           475580\n",
       "119         Russia           461234"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print number of times each county is duplicated, sort by descending order.\n",
    "temperature_df.groupby('Country')['Country'].count().reset_index(name=\"Duplicate_Count\").sort_values(\"Duplicate_Count\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687289, 7)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We are only interested in rows with the Country column equal to 'United States'.  Filtering for 'United States' provides a data frame with 687289 rows, matching the previous function of counting duplicate Country values.\n",
    "temperature_df = temperature_df[temperature_df['Country'] == 'United States']\n",
    "#Print shape after removeing non-US Countries\n",
    "temperature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                                   0\n",
       "AverageTemperature               25765\n",
       "AverageTemperatureUncertainty    25765\n",
       "City                                 0\n",
       "Country                              0\n",
       "Latitude                             0\n",
       "Longitude                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List the sum of null values in each column\n",
    "temperature_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47723</th>\n",
       "      <td>1834-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137067</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137068</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137069</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137070</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47723  1834-01-01                 NaN                            NaN  Abilene   \n",
       "137067 1743-12-01                 NaN                            NaN    Akron   \n",
       "137068 1744-01-01                 NaN                            NaN    Akron   \n",
       "137069 1744-02-01                 NaN                            NaN    Akron   \n",
       "137070 1744-03-01                 NaN                            NaN    Akron   \n",
       "\n",
       "              Country Latitude Longitude  \n",
       "47723   United States   32.95N   100.53W  \n",
       "137067  United States   40.99N    80.95W  \n",
       "137068  United States   40.99N    80.95W  \n",
       "137069  United States   40.99N    80.95W  \n",
       "137070  United States   40.99N    80.95W  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display a sample of the 25765 rows with null values in the AverageTemperature column\n",
    "temperature_df[temperature_df.AverageTemperature.isnull()].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                               0\n",
       "AverageTemperature               0\n",
       "AverageTemperatureUncertainty    0\n",
       "City                             0\n",
       "Country                          0\n",
       "Latitude                         0\n",
       "Longitude                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop rows with null values in the AverageTemperature column.  Rerunning the function to display null value totals indicates there are no longer any null values found.\n",
    "temperature_df = temperature_df.dropna(subset=['AverageTemperature'])\n",
    "temperature_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661524, 7)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the final size of the temperature_df dataframe.  \n",
    "temperature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#temperature_df.write.parquet(\"sas_data\")\n",
    "#temperature_df=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "\n",
    "##### demographics_df\n",
    "* Determine the number of unique race values exist for each City, State combination and add that value to new column called 'Unique_Races'\n",
    "* Pivot the Race and Count values of each City, State combination into a new dataframe called 'City_Race_Table'\n",
    "\n",
    "#### immigration_df\n",
    "* Add a new column titled 'arrival_date' by converting values in column 'i94addr' from double type to data type date\n",
    "* Add columns for port_of_entry_city and port_of_entry_state by joining the i94PortsOfEntryCodes sources from the I94 Immigration Data dictionary\n",
    "\n",
    "#### temperature_df\n",
    "* Convert the dt column to a date data type\n",
    "* Drop where the Country column does not equal \"United States\"\n",
    "* Drop rows containing a null value in the AverageTemperature column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The data model is composed of the fact table and dimension tables listed below.  Analysts are able to query information about US immigration patterns and demographic information about the cities where immigrants are arriving. The racial make up of US cities is found in a dedicated dimension table, allowing analysts to efficiently develope insights into a city's cultural make up without filtering duplicate rows of the city_demographics_dim table.  Immigration arrival times are also found in a dedicated table, allowing the user to efficiently filter for specific date parameters.\n",
    "\n",
    "#### Fact Table:\n",
    "_immigration_fact_\n",
    "\n",
    "#### Dimension Tables:\n",
    "* _immigration_arrival_time_dim_\n",
    "* _city_demographics_dim_\n",
    "* _city_races_dim_\n",
    "* _temperature_dim_\n",
    "\n",
    "Columns of each able listed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "* Data sets are loaded from csv or sas files\n",
    "* Each of the three data sets are cleaned and prepped for loading into final database tables\n",
    "* Final data model tables are created using the cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>location</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code                  location state\n",
       "0  ALC                     ALCAN    AK\n",
       "1  ANC                 ANCHORAGE    AK\n",
       "2  BAR  BAKER AAF - BAKER ISLAND    AK\n",
       "3  DAC             DALTONS CACHE    AK\n",
       "4  PIZ    DEW STATION PT LAY DEW    AK"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portCode = pd.read_csv('i94PortsOfEntryCodes.csv')\n",
    "portCode.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### _immigration_fact_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_df = etl_functions.add_arrivalDate_CityState_to_immigration_df(spark, immigration_df)\n",
    "#Stage immigration data\n",
    "immigration_df.createOrReplaceTempView('immigration_fact_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+--------------+------------+------------------+-------------------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|arrival_date_1|arrival_date|port_of_entry_city|port_of_entry_state|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+--------------+------------+------------------+-------------------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|    2016-04-30|  2016-04-30|       LOS ANGELES|                 CA|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|    2016-04-30|  2016-04-30|       LOS ANGELES|                 CA|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|    2016-04-30|  2016-04-30|       LOS ANGELES|                 CA|\n",
      "|5748520.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     F|  null|     DL|9.495645143E10|00040|      B1|    2016-04-30|  2016-04-30|       LOS ANGELES|                 CA|\n",
      "|5748521.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  28.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1988.0|10292016|     M|  null|     DL|9.495638813E10|00040|      B1|    2016-04-30|  2016-04-30|       LOS ANGELES|                 CA|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+--------------+------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096313, 32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_df.count(), len(immigration_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_fact = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        cicid AS id, \n",
    "        i94yr AS year,\n",
    "        i94mon AS numeric_month,\n",
    "        i94cit AS birth_country,\n",
    "        i94res AS residence_country,\n",
    "        i94port AS admission_port,\n",
    "        arrival_date,\n",
    "        i94mode AS transportation_mode,\n",
    "        i94addr AS arrival_state,\n",
    "        depdate AS departure_date,\n",
    "        i94bir AS age,\n",
    "        i94visa AS visa_code,\n",
    "        count AS count,\n",
    "        dtadfile As date_added,\n",
    "        visapost AS visa_post,\n",
    "        occup AS occupation,\n",
    "        entdepa AS arrival_flag,\n",
    "        entdepd AS departure_flag,\n",
    "        entdepu AS update_flag,\n",
    "        matflag AS match_flag,\n",
    "        biryear AS birth_year,\n",
    "        dtaddto AS stay_date, \n",
    "        gender AS gender,\n",
    "        insnum AS ins_number,\n",
    "        airline AS airline,\n",
    "        admnum AS admission_number,\n",
    "        fltno AS flight_number,\n",
    "        visatype AS visa_type,\n",
    "        port_of_entry_city AS city,\n",
    "        port_of_entry_state AS state\n",
    "    FROM immigration_fact_table\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_fact.createOrReplaceTempView('immigration_fact_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------------+-------------+-----------------+--------------+------------+-------------------+-------------+--------------+----+---------+-----+----------+---------+----------+------------+--------------+-----------+----------+----------+---------+------+----------+-------+----------------+-------------+---------+-----------+-----+\n",
      "|       id|  year|numeric_month|birth_country|residence_country|admission_port|arrival_date|transportation_mode|arrival_state|departure_date| age|visa_code|count|date_added|visa_post|occupation|arrival_flag|departure_flag|update_flag|match_flag|birth_year|stay_date|gender|ins_number|airline|admission_number|flight_number|visa_type|       city|state|\n",
      "+---------+------+-------------+-------------+-----------------+--------------+------------+-------------------+-------------+--------------+----+---------+-----+----------+---------+----------+------------+--------------+-----------+----------+----------+---------+------+----------+-------+----------------+-------------+---------+-----------+-----+\n",
      "|5748517.0|2016.0|          4.0|        245.0|            438.0|           LOS|  2016-04-30|                1.0|           CA|       20582.0|40.0|      1.0|  1.0|  20160430|      SYD|      null|           G|             O|       null|         M|    1976.0| 10292016|     F|      null|     QF|  9.495387003E10|        00011|       B1|LOS ANGELES|   CA|\n",
      "|5748518.0|2016.0|          4.0|        245.0|            438.0|           LOS|  2016-04-30|                1.0|           NV|       20591.0|32.0|      1.0|  1.0|  20160430|      SYD|      null|           G|             O|       null|         M|    1984.0| 10292016|     F|      null|     VA|  9.495562283E10|        00007|       B1|LOS ANGELES|   CA|\n",
      "|5748519.0|2016.0|          4.0|        245.0|            438.0|           LOS|  2016-04-30|                1.0|           WA|       20582.0|29.0|      1.0|  1.0|  20160430|      SYD|      null|           G|             O|       null|         M|    1987.0| 10292016|     M|      null|     DL|  9.495640653E10|        00040|       B1|LOS ANGELES|   CA|\n",
      "|5748520.0|2016.0|          4.0|        245.0|            438.0|           LOS|  2016-04-30|                1.0|           WA|       20588.0|29.0|      1.0|  1.0|  20160430|      SYD|      null|           G|             O|       null|         M|    1987.0| 10292016|     F|      null|     DL|  9.495645143E10|        00040|       B1|LOS ANGELES|   CA|\n",
      "|5748521.0|2016.0|          4.0|        245.0|            438.0|           LOS|  2016-04-30|                1.0|           WA|       20588.0|28.0|      1.0|  1.0|  20160430|      SYD|      null|           G|             O|       null|         M|    1988.0| 10292016|     M|      null|     DL|  9.495638813E10|        00040|       B1|LOS ANGELES|   CA|\n",
      "+---------+------+-------------+-------------+-----------------+--------------+------------+-------------------+-------------+--------------+----+---------+-----+----------+---------+----------+------------+--------------+-----------+----------+----------+---------+------+----------+-------+----------------+-------------+---------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_fact.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### _immigration_arrival_time_dim_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create immigration_arrival_time_dim dimension table\n",
    "immigration_arrival_time_dim = spark.sql(\"\"\"\n",
    "    SELECT id, arrival_date, YEAR(arrival_date) as year,MONTH(arrival_date) as month,DAY(arrival_date) as day,WEEKOFYEAR(arrival_date) as week,DAYOFWEEK(arrival_date) as weekday,DAYOFYEAR(arrival_date) as day_of_year\n",
    "    FROM immigration_fact_table\n",
    "\"\"\")\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+----+-----+---+----+-------+-----------+\n",
      "|       id|arrival_date|year|month|day|week|weekday|day_of_year|\n",
      "+---------+------------+----+-----+---+----+-------+-----------+\n",
      "|5748517.0|  2016-04-30|2016|    4| 30|  17|      7|        121|\n",
      "|5748518.0|  2016-04-30|2016|    4| 30|  17|      7|        121|\n",
      "|5748519.0|  2016-04-30|2016|    4| 30|  17|      7|        121|\n",
      "|5748520.0|  2016-04-30|2016|    4| 30|  17|      7|        121|\n",
      "|5748521.0|  2016-04-30|2016|    4| 30|  17|      7|        121|\n",
      "+---------+------------+----+-----+---+----+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_arrival_time_dim.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### _city_demographics_dim_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "demographics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographics_df_spark = spark.createDataFrame(demographics_df)\n",
    "demographics_df_spark.createOrReplaceTempView(\"demographics_dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "city_demographics_dim = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        City,\n",
    "        State,\n",
    "        `Median Age` AS median_age,\n",
    "        `Male Population` AS male_population,\n",
    "        `Female Population` AS female_population,\n",
    "        `Total Population` AS total_population,\n",
    "        `Number of Veterans` AS number_of_veterans,\n",
    "        `Foreign-born` AS foreign_born,\n",
    "        `Average Household Size` AS average_household_size,\n",
    "        `State Code` AS state_code\n",
    "    FROM demographics_dim\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+\n",
      "|            City|        State|median_age|male_population|female_population|total_population|number_of_veterans|foreign_born|average_household_size|state_code|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+\n",
      "|   Silver Spring|     Maryland|      33.8|        40601.0|          41862.0|           82463|            1562.0|     30908.0|                   2.6|        MD|\n",
      "|          Quincy|Massachusetts|      41.0|        44129.0|          49500.0|           93629|            4147.0|     32935.0|                  2.39|        MA|\n",
      "|          Hoover|      Alabama|      38.5|        38040.0|          46799.0|           84839|            4819.0|      8229.0|                  2.58|        AL|\n",
      "|Rancho Cucamonga|   California|      34.5|        88127.0|          87105.0|          175232|            5821.0|     33878.0|                  3.18|        CA|\n",
      "|          Newark|   New Jersey|      34.6|       138040.0|         143873.0|          281913|            5829.0|     86253.0|                  2.73|        NJ|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_demographics_dim.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### _temperature_dim_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaned_temperature_df = etl_functions.clean_temp_df(spark, temperature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 661524 entries, 47555 to 8439246\n",
      "Data columns (total 7 columns):\n",
      "dt                               661524 non-null datetime64[ns]\n",
      "AverageTemperature               661524 non-null float64\n",
      "AverageTemperatureUncertainty    661524 non-null float64\n",
      "City                             661524 non-null object\n",
      "Country                          661524 non-null object\n",
      "Latitude                         661524 non-null object\n",
      "Longitude                        661524 non-null object\n",
      "dtypes: datetime64[ns](1), float64(2), object(4)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_temperature_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 661524 entries, 47555 to 8439246\n",
      "Data columns (total 7 columns):\n",
      "dt                               661524 non-null datetime64[ns]\n",
      "AverageTemperature               661524 non-null float64\n",
      "AverageTemperatureUncertainty    661524 non-null float64\n",
      "City                             661524 non-null object\n",
      "Country                          661524 non-null object\n",
      "Latitude                         661524 non-null object\n",
      "Longitude                        661524 non-null object\n",
      "dtypes: datetime64[ns](1), float64(2), object(4)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "temperature_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create a spark dataframe from the existing pandas dataframe\n",
    "temperature_df_spark = spark.createDataFrame(cleaned_temperature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_df_spark.createOrReplaceTempView(\"temperature_dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_dim = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        dt AS Date,\n",
    "        City AS City,\n",
    "        Country AS Country,\n",
    "        Latitude AS Latitude,\n",
    "        AverageTemperatureUncertainty as AverageTemperatureUncertainty\n",
    "    FROM temperature_Dim\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------------+--------+-----------------------------+\n",
      "|               Date|   City|      Country|Latitude|AverageTemperatureUncertainty|\n",
      "+-------------------+-------+-------------+--------+-----------------------------+\n",
      "|1820-01-01 00:00:00|Abilene|United States|  32.95N|                        3.217|\n",
      "|1820-02-01 00:00:00|Abilene|United States|  32.95N|                        2.853|\n",
      "|1820-03-01 00:00:00|Abilene|United States|  32.95N|                        2.395|\n",
      "|1820-04-01 00:00:00|Abilene|United States|  32.95N|                        2.202|\n",
      "|1820-05-01 00:00:00|Abilene|United States|  32.95N|                        2.036|\n",
      "+-------------------+-------+-------------+--------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_dim.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### _city_races_dim_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "city_races_function = etl_functions.add_raceCount_to_demographics(spark, demographics_df)\n",
    "city_races_function.createOrReplaceTempView(\"city_races_function_spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "city_races_dim = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        City AS City,\n",
    "        State AS State,\n",
    "        `American Indian and Alaska Native` AS American_Indian_and_Alaska_Native,\n",
    "        Asian AS Asian,\n",
    "        `Black or African-American` AS Black_or_African_American,\n",
    "        `Hispanic or Latino` AS Hispanic_or_Latino,\n",
    "        White AS White\n",
    "    FROM city_races_function_spark\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|                City|   State|American_Indian_and_Alaska_Native|Asian|Black_or_African_American|Hispanic_or_Latino| White|\n",
      "+--------------------+--------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|          Cincinnati|    Ohio|                             3362| 7633|                   133430|              9121|162245|\n",
      "|           Lynchburg|Virginia|                             1024| 2910|                    23271|              2689| 53727|\n",
      "|         Kansas City|  Kansas|                             2749| 7301|                    40177|             44342| 96113|\n",
      "|Louisville/Jeffer...|Kentucky|                             4585|18601|                   151256|             28712|456451|\n",
      "|              Dayton|    Ohio|                             2010| 1885|                    57280|              4945| 86016|\n",
      "+--------------------+--------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_races_dim.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def quality_check(df, df_name):\n",
    "    row_count = df.count()\n",
    "    if(row_count == 0):\n",
    "        print(f\"Data quality check failed for {df_name} table, zero rows found.\")\n",
    "    else:\n",
    "        print(f\"Data quality check passed for {df_name} table, {row_count} rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration fact table, 3096313 rows found.\n",
      "Data quality check passed for immigration arrival time dimension table, 3096313 rows found.\n",
      "Data quality check passed for city demographics dimension table, 2891 rows found.\n",
      "Data quality check passed for temperature dimension table, 661524 rows found.\n",
      "Data quality check passed for city races dimension table, 596 rows found.\n"
     ]
    }
   ],
   "source": [
    "#Each table is processed by the quality_check function to confirm it contains content \n",
    "dataFrames = {\n",
    "    'immigration fact':immigration_fact,\n",
    "    'immigration arrival time dimension':immigration_arrival_time_dim,\n",
    "    'city demographics dimension':city_demographics_dim,\n",
    "    'temperature dimension':temperature_dim,\n",
    "    'city races dimension':city_races_dim\n",
    "}\n",
    "for df_name, df in dataFrames.items():\n",
    "    quality_check(df, df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+--------+----------------+\n",
      "|       id|  year|state_code|    city|total_population|\n",
      "+---------+------+----------+--------+----------------+\n",
      "|5926534.0|2016.0|        NY| Buffalo|          258066|\n",
      "|6050833.0|2016.0|        NY| Buffalo|          258066|\n",
      "|6058352.0|2016.0|        NY| Buffalo|          258066|\n",
      "|5937309.0|2016.0|        NY| Buffalo|          258066|\n",
      "|5918677.0|2016.0|        NY| Buffalo|          258066|\n",
      "| 481083.0|2016.0|        OR|Portland|          632187|\n",
      "| 499648.0|2016.0|        OR|Portland|          632187|\n",
      "| 514502.0|2016.0|        OR|Portland|          632187|\n",
      "| 691132.0|2016.0|        OR|Portland|          632187|\n",
      "| 692462.0|2016.0|        OR|Portland|          632187|\n",
      "+---------+------+----------+--------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_demographics_dim.createOrReplaceTempView(\"city_demographics\")\n",
    "#The query below tests the illustrates the ability to join two tables in the data model using the state and city fields\n",
    "quality_test_joined_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "    immigration_fact_table.id,\n",
    "    immigration_fact_table.year,\n",
    "    city_demographics.state_code,\n",
    "    city_demographics.city,\n",
    "    city_demographics.total_population\n",
    "    FROM \n",
    "    immigration_fact_table \n",
    "    INNER JOIN city_demographics\n",
    "    ON immigration_fact_table.state = city_demographics.state_code\n",
    "    AND LOWER(immigration_fact_table.city) = LOWER(city_demographics.city)\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_fact.createOrReplaceTempView('imm_fact')\n",
    "city_demographics_dim.createOrReplaceTempView('city_dim')\n",
    "temperature_dim.createOrReplaceTempView('temp_dim')\n",
    "city_races_dim.createOrReplaceTempView('races_dim')\n",
    "immigration_arrival_time_dim.createOrReplaceTempView('arrival_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#This function counts the number of null values in the primary keys of each table and prints a message indicating if any are found or not.\n",
    "def countNullValues(tables_keys, spark):\n",
    "    for table, column in tables_keys.items():\n",
    "        null_count = spark.sql(f\"SELECT COUNT(*) FROM {table} WHERE {column[0]} IS NULL\")\n",
    "        if(null_count.head()[0] > 0):\n",
    "            print(f\"Data quality null values check failed for {table} table, {null_count} null rows found.\")\n",
    "        else:\n",
    "            print(f\"Data quality null values check passed for {table} table.\")                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality null values check passed for imm_fact table.\n",
      "Data quality null values check passed for arrival_dim table.\n",
      "Data quality null values check passed for city_dim table.\n",
      "Data quality null values check passed for temp_dim table.\n",
      "Data quality null values check passed for races_dim table.\n"
     ]
    }
   ],
   "source": [
    "tables_keys = {'imm_fact':['id'],'arrival_dim':['id'],'city_dim':['state'],'city_dim':['state_code'],'temp_dim':['date'],'races_dim':['state']}\n",
    "countNullValues(tables_keys, spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Fact Table\n",
    "_immigration_fact_\n",
    "_Column Name - Description_\n",
    "* id - record ID\n",
    "* year - 4 digit year\n",
    "* numeric_month - Numeric month\n",
    "* birth_country - 3 digit code for immigrant country of birth\n",
    "* residence_country - 3 digit code for immigrant country of residence\n",
    "* admission_port - Port of admission \n",
    "* arrival_date - Arrival Date in the USA\n",
    "* transportation_mode - Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)\n",
    "* arrival_state - USA State of arrival\n",
    "* departure_date - Departure Date from the USA\n",
    "* age - Age of Respondent in Years\n",
    "* visa_code - Visa codes collapsed into three categories\n",
    "* count - Field used for summary statistics\n",
    "* date_added - Character Date Field - Date added to I-94 Files\n",
    "* visa_post - Department of State where where Visa was issued\n",
    "* occupation - Occupation that will be performed in U.S\n",
    "* arrival_flag - Arrival Flag - admitted or paroled into the U.S.\n",
    "* departure_flag - Departure Flag - Departed, lost I-94 or is deceased\n",
    "* update_flag - Update Flag - Either apprehended, overstayed, adjusted to perm residence\n",
    "* match_flag - Match flag - Match of arrival and departure records\n",
    "* birth_year - 4 digit year of birth\n",
    "* stay_date - Character Date Field - Date to which admitted to U.S. (allowed to stay until)\n",
    "* gender - Non-immigrant sex\n",
    "* ins_number - INSnumber \n",
    "* airline - Airline used to arrive in U.S.\n",
    "* admission_number - Admission Number\n",
    "* flight_number - Flight number of Airline used to arrive in U.S.\n",
    "* visa_type - Class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n",
    "* City - City of entry\n",
    "* State - State of entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dimension Tables:\n",
    "\n",
    "##### _immigration_arrival_time_dim_\n",
    "Arrival date of each immigration record is split into a more granular data set to allow an analyst to easily filter a query by a more specific date parameter.  The table can be joined on the id column.\n",
    "\n",
    "* id - Unique record id \n",
    "* date - original arrival date from immigration_fact table\n",
    "* year - original arrival year\n",
    "* month - original arrival month\n",
    "* day - original arrival day\n",
    "* week - original arrival week\n",
    "* weekday - original arrival weekday\n",
    "\n",
    "##### _city_demographics_dim_\n",
    "This table is composed of original US Census Bureau's 2015 American Community Survey. The Unique_Races column has been added to provide additional insight into a city's cultural make up.  The table can be joined on the city and state columns.\n",
    "* city\n",
    "* state\n",
    "* median Age\n",
    "* male Population\n",
    "* female Population\n",
    "* total Population\n",
    "* number of Veterans\n",
    "* foreign-born\n",
    "* average Household Size\n",
    "* state Code\n",
    "* race\n",
    "* count\n",
    "* unique_races\n",
    "\n",
    "##### _city_races_dim_\n",
    "The types of races that are accounted for in each city included in the city_demographics_dim are pivoted into columns.  The table can be joined to other tables using the city and state columns.\n",
    "* city\n",
    "* ctate\n",
    "* american Indian and Alaska Native\n",
    "* asian\n",
    "* black or African-American\n",
    "* hispanic or Latino\n",
    "* white\n",
    "\n",
    "##### _temperature_dim_\n",
    "Historic temperatures of cities within the United States are included.  The table can be joined to other tables using the city column.\n",
    "* dt - date temperature was recorded\n",
    "* averageTemperature\n",
    "* averageTemperatureUncertainty\n",
    "* city\n",
    "* country\n",
    "* latitude\n",
    "* longitude\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 5: Complete Project Write Up\n",
    "\n",
    "#### Rationale for the choice of tools and technologies used in this project\n",
    "\n",
    "* This project utilized Sparkpy and the pandas python library to manipulate and organize data from three sources.  Sparkpy was uniquely valuable to the project due to its ability to process large amounts of data. Pandas was also very useful in efficiently evaluating and cleaning the raw data. Utilizing both tools within a Jupyter Notebook creates a very user-friendly environment where raw data is stage, explored, and eventually structure, all within a single interface.  Other users can see all steps taken to load and prepare data, allowing a transparent and clear understanding of the ETL process and scope of data available to all eventual users. \n",
    "* To accommodate a user's preference for the latest data, the data source files should be updated as new files are made available. Additional files can be appended to existing tables and processed per the existing ETL procedure. \n",
    "\n",
    "#### Alternative Scenarios\n",
    "\n",
    "* If the amount of data was increased by 100x the ETL would need to rely more on Sparkpy and less on Pandas.  Several evaluation and cleaning functions would need to employ Sparkpy functions due to their ability to process large amounts of data.  Depending on an organization’s requirements, use of a cloud service such as AWS EMR may also be required to reduce the processing time by increasing the number of machines being used to process the data. \n",
    "* The ETL within this Jupyter Notebook can be executed on a scheduled basis using external plugins such as Apache Airflow or the Papermill library.  Doing so would allow automated workflows to populate databases on a schedule to accommodate an organization's data communication requirements such as dashboards, reports, and alerts. \n",
    "* To share the database with a wider user group, tools such as an Amazon S3 Bucket could be employed to store and provide user access across an organization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
